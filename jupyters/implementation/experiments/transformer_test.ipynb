{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def adding_module_path():\n",
    "    module_path = os.path.abspath(os.path.sep.join([\"..\"]*3))\n",
    "\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "adding_module_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.instances.neural_nets.transformer_with_dense_head import TransformerWithDenseHeadExperiment\n",
    "from src.data_loading.get_dataset_object_from import get_dataset_all\n",
    "from src.utils.from_dataset_arrays import from_dataset_dataframe\n",
    "from src.models.transformer.pooling_strategy import TransformerPoolingStrategySelection, pooling_strategy_dictionary\n",
    "from src.types.transformer_name import TransformerName\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_AUTHORS = 6\n",
    "NUMBER_OF_SENTENCES = 3\n",
    "NORMALIZED_VALUE = 1000\n",
    "SEQUENCE = 50\n",
    "TRAINABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (1, 5), (2, 3), (2, 5)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.product([1, 2], [3, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating shorting method with min = 3\n",
      "Creating lemma method with instance <WordNetLemmatizer>\n",
      "Loading dataset from=C:\\Users\\Vojta\\Desktop\\diploma\\data\\gutenberg\\6Authors\\Sentence3\\data.csv\n"
     ]
    }
   ],
   "source": [
    "data, paths = get_dataset_all(NUMBER_OF_AUTHORS, NUMBER_OF_SENTENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<MapDataset shapes: (<unknown>, <unknown>), types: (tf.string, tf.int32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Vojta\\\\Desktop\\\\diploma\\\\data\\\\gutenberg\\\\6Authors\\\\Sentence3\\\\data.csv',\n",
       " 'C:\\\\Users\\\\Vojta\\\\Desktop\\\\diploma\\\\data\\\\gutenberg\\\\6Authors\\\\Sentence3\\\\authors.csv')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = from_dataset_dataframe(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['le'] = all_data['text'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['le'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(all_data, x='le', color='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments.experiment_run_wrapper import ExperimentRunWrapper\n",
    "from src.experiments.settings import LearningSettings\n",
    "from src.tokenizers.transformer_tokenizer import TransformerTokenizer\n",
    "from src.encoder.create_encoder_from_path import create_encoder_from_path\n",
    "from transformers import TFAutoModel, AutoConfig\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from src.tokenizers.prepare_dataset_from_tokenizer import prepare_dataset_from_tokenizer\n",
    "from src.models.transformer.bert_pooling_layer import BertPoolingLayer\n",
    "import time\n",
    "from src.experiments.experiment_summarization import ExperimentSummarization\n",
    "from src.types.experiment_summarization_fields import ExperimentSummarizationFields\n",
    "from src.config.learning_config import TRANSFORMER_EPOCHS\n",
    "from src.experiments.descriptions.create_description import (\n",
    "    create_description_for_transformer_with_dense_head\n",
    ")\n",
    "import os\n",
    "from src.config.config import TEXT_COLUMN, LABEL_COLUMN, VALIDATION_SIZE\n",
    "from src.experiments.experiment_description import ExperimentDescription\n",
    "from src.types.transformer_pooling import TransformerPooling\n",
    "from src.types.prediction_model_type import PredictionModelType\n",
    "from src.types.net_type import NetType\n",
    "from src.types.embedding_type import EmbeddingType\n",
    "from src.types.processing_type import PreprocessingType\n",
    "import time\n",
    "from src.data_loading.get_dataset_object_from import get_dataset_all\n",
    "from src.utils.from_dataset_arrays import from_dataset_dataframe\n",
    "from src.utils.split_dataframe import split_dataframe\n",
    "from src.utils.normalize_dataframe_to_size import normalize_dataframe_to_size\n",
    "from src.utils.create_dataset_from_dataframe import create_dataset_from_Xy\n",
    "import pandas as pd\n",
    "from src.utils.generate_random_stamp import generator_random_stamp\n",
    "from src.types.transformer_pooling import TransformerPooling\n",
    "from src.models.transformer.pooling_strategy import pooling_strategy_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = TransformerName..value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = LearningSettings()\n",
    "settings.epochs = TRANSFORMER_EPOCHS\n",
    "data_path, authors_path = paths\n",
    "\n",
    "data_normalized = normalize_dataframe_to_size(all_data, NORMALIZED_VALUE)\n",
    "X_train, X_test, y_train, y_test = split_dataframe(data_normalized)\n",
    "df = pd.DataFrame()\n",
    "df[TEXT_COLUMN] = X_train\n",
    "df[LABEL_COLUMN] = y_train\n",
    "X_train, X_val, y_train, y_val = split_dataframe(df, VALIDATION_SIZE)\n",
    "\n",
    "train_ds = create_dataset_from_Xy(X_train, y_train)\n",
    "test_ds = create_dataset_from_Xy(X_test, y_test)\n",
    "val_ds = create_dataset_from_Xy(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = pooling_strategy_dictionary[TransformerPoolingStrategySelection.Pooler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TransformerTokenizer(\n",
    "    model_name.value, create_encoder_from_path(authors_path), max_len=SEQUENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_dataset_from_tokenizer(X_train, tokenizer)\n",
    "test_ds = prepare_dataset_from_tokenizer(X_test, tokenizer)\n",
    "val_ds = prepare_dataset_from_tokenizer(X_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)\n",
    "transformer = TFAutoModel.from_config(config)\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(SEQUENCE,), name=\"input_ids\", dtype=\"int32\")\n",
    "mask = tf.keras.layers.Input(shape=(SEQUENCE,), name=\"attention_mask\", dtype=\"int32\")\n",
    "\n",
    "\n",
    "embeddings = transformer(input_ids, attention_mask=mask)['last_hidden_state']  # we only keep tensor 0 (last_hidden_state)\n",
    "#X = BertPoolingLayer()(embeddings, *pooling_strategy)\n",
    "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)  # reduce tensor dimensionality\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.Dense(128, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "y = tf.keras.layers.Dense(NUMBER_OF_AUTHORS, activation='softmax', name='outputs')(X)  # adjust based on number of sentiment classes\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "\n",
    "model.layers[2].trainable = TRAINABLE\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=settings.loss,\n",
    "    optimizer=settings.optimizer,\n",
    "    metrics=settings.metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_ds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "deac0217989ddcfa4345bc236e90ab22a38c5ad7d8517b867015082eaa3f672d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
